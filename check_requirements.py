import json
from pathlib import Path

print("=" * 80)
print("KIá»‚M TRA YÃŠU Cáº¦U MINI PROJECT")
print("=" * 80)

# Load metrics
DATA_PROCESSED = Path("data/processed")

baseline = json.load(open(DATA_PROCESSED / "metrics.json"))
self_training = json.load(open(DATA_PROCESSED / "metrics_self_training.json"))
co_training = json.load(open(DATA_PROCESSED / "metrics_co_training.json"))

print("\n" + "="*80)
print("YÃŠU Cáº¦U 1: SELF-TRAINING")
print("="*80)

st_cfg = self_training.get('st_cfg', {})
st_history = self_training.get('history', [])
st_test = self_training.get('test_metrics', {})

print(f"\nâœ… ÄÃ£ huáº¥n luyá»‡n Self-Training:")
print(f"   - Tau (Ï„): {st_cfg.get('tau', 'N/A')}")
print(f"   - Iterations: {len(st_history)}")
print(f"   - Test Accuracy: {st_test.get('accuracy', 0):.4f}")
print(f"   - Test F1-Macro: {st_test.get('f1_macro', 0):.4f}")

print(f"\nâš ï¸  THIáº¾U - Thay Ä‘á»•i ngÆ°á»¡ng Ï„:")
print(f"   - Hiá»‡n chá»‰ cÃ³ Ï„=0.9")
print(f"   - Cáº§n: Thá»­ Ï„ âˆˆ {{0.8, 0.85, 0.9, 0.95}} vÃ  so sÃ¡nh")

print(f"\nâš ï¸  THIáº¾U - Biá»ƒu Ä‘á»“ diá»…n biáº¿n:")
print(f"   - CÃ³ history data: âœ“")
print(f"   - CÃ³ visualization code: âœ“ (trong visualization_utils.py)")
print(f"   - Cáº§n: Notebook hoáº·c script táº¡o biá»ƒu Ä‘á»“")

print(f"\nâœ… So sÃ¡nh vá»›i baseline:")
baseline_acc = baseline.get('test_accuracy', 0)
baseline_f1 = baseline.get('test_f1_macro', 0)
st_acc = st_test.get('accuracy', 0)
st_f1 = st_test.get('f1_macro', 0)

print(f"   Baseline:      Acc={baseline_acc:.4f}, F1={baseline_f1:.4f}")
print(f"   Self-Training: Acc={st_acc:.4f}, F1={st_f1:.4f}")
print(f"   Improvement:   Acc={st_acc-baseline_acc:+.4f}, F1={st_f1-baseline_f1:+.4f}")

print(f"\nâš ï¸  THIáº¾U - PhÃ¢n tÃ­ch per-class:")
print(f"   - CÃ³ classification report: âœ“")
print(f"   - Cáº§n: So sÃ¡nh tá»«ng class vá»›i baseline")

print("\n" + "="*80)
print("YÃŠU Cáº¦U 2: CO-TRAINING")
print("="*80)

ct_cfg = co_training.get('ct_cfg', {})
ct_history = co_training.get('history', [])
ct_test = co_training.get('test_metrics', {})

print(f"\nâœ… ÄÃ£ huáº¥n luyá»‡n Co-Training:")
print(f"   - Tau (Ï„): {ct_cfg.get('tau', 'N/A')}")
print(f"   - Iterations: {len(ct_history)}")
print(f"   - Test Accuracy: {ct_test.get('accuracy', 0):.4f}")
print(f"   - Test F1-Macro: {ct_test.get('f1_macro', 0):.4f}")

print(f"\nâŒ THIáº¾U - MÃ´ táº£ 2 views:")
print(f"   - Cáº§n document: View 1 (features gÃ¬), View 2 (features gÃ¬)")
print(f"   - Giáº£i thÃ­ch táº¡i sao 2 views Ä‘á»™c láº­p")

if ct_history:
    total_m1 = sum(h.get('n_added_m1', 0) for h in ct_history)
    total_m2 = sum(h.get('n_added_m2', 0) for h in ct_history)
    print(f"\nâš ï¸  Váº¤N Äá»€ - Pseudo-label exchange:")
    print(f"   - M1â†’M2: {total_m1} samples")
    print(f"   - M2â†’M1: {total_m2} samples")
    if total_m1 == 0 and total_m2 == 0:
        print(f"   âŒ KHÃ”NG CÃ“ TRAO Äá»”I! Cáº§n kiá»ƒm tra láº¡i config")

print(f"\nâš ï¸  THIáº¾U - Biá»ƒu Ä‘á»“ diá»…n biáº¿n:")
print(f"   - CÃ³ history data: âœ“")
print(f"   - CÃ³ visualization code: âœ“")
print(f"   - Cáº§n: Notebook hoáº·c script táº¡o biá»ƒu Ä‘á»“")

print(f"\nâœ… So sÃ¡nh vá»›i baseline & self-training:")
ct_acc = ct_test.get('accuracy', 0)
ct_f1 = ct_test.get('f1_macro', 0)

print(f"   Baseline:      Acc={baseline_acc:.4f}, F1={baseline_f1:.4f}")
print(f"   Self-Training: Acc={st_acc:.4f}, F1={st_f1:.4f}")
print(f"   Co-Training:   Acc={ct_acc:.4f}, F1={ct_f1:.4f}")

print("\n" + "="*80)
print("YÃŠU Cáº¦U 3: SO SÃNH THAM Sá»")
print("="*80)

# Check for multiple tau configs
metrics_files = list(DATA_PROCESSED.glob("metrics*.json"))
print(f"\nâŒ THIáº¾U - Thá»­ nghiá»‡m nhiá»u Ï„:")
print(f"   - Hiá»‡n cÃ³: {len(metrics_files)} config")
print(f"   - Cáº§n: Ãt nháº¥t 3 giÃ¡ trá»‹ Ï„ khÃ¡c nhau (0.8, 0.9, 0.95)")

print(f"\nâš ï¸  CÃ¡c thá»­ nghiá»‡m khÃ¡c (optional):")
print(f"   - Thay Ä‘á»•i label fraction: CÃ³ thá»ƒ lÃ m âœ“")
print(f"   - Thá»­ model khÃ¡c: ChÆ°a lÃ m")
print(f"   - Thá»­ view khÃ¡c: ChÆ°a lÃ m")

print("\n" + "="*80)
print("YÃŠU Cáº¦U 4: DASHBOARD STREAMLIT")
print("="*80)

dashboard_file = Path("app.py")
viz_utils = Path("src/visualization_utils.py")

print(f"\nâœ… Dashboard Streamlit:")
print(f"   - File app.py: {'âœ“' if dashboard_file.exists() else 'âŒ'}")
print(f"   - Visualization utils: {'âœ“' if viz_utils.exists() else 'âŒ'}")
print(f"   - 5 pages: Overview, Comparison, Self-Training, Co-Training, Predictions")

if dashboard_file.exists():
    print(f"\n   Cháº¡y: streamlit run app.py")

print("\n" + "="*80)
print("Tá»”NG Káº¾T")
print("="*80)

completed = []
partial = []
missing = []

completed.append("âœ… Self-Training Ä‘Ã£ cháº¡y (Ï„=0.9)")
completed.append("âœ… Co-Training Ä‘Ã£ cháº¡y (Ï„=0.9)")  
completed.append("âœ… So sÃ¡nh baseline vs semi-supervised")
completed.append("âœ… Dashboard Streamlit Ä‘Ã£ cÃ³")
completed.append("âœ… Visualization utilities Ä‘Ã£ cÃ³")

partial.append("âš ï¸  Self-Training: CÃ³ history nhÆ°ng thiáº¿u biá»ƒu Ä‘á»“")
partial.append("âš ï¸  Co-Training: CÃ³ history nhÆ°ng thiáº¿u biá»ƒu Ä‘á»“")
partial.append("âš ï¸  Co-Training: Pseudo-label exchange = 0")

missing.append("âŒ Thá»­ nghiá»‡m nhiá»u Ï„ (0.8, 0.85, 0.95)")
missing.append("âŒ Biá»ƒu Ä‘á»“ diá»…n biáº¿n (plots/charts)")
missing.append("âŒ PhÃ¢n tÃ­ch per-class performance")
missing.append("âŒ Document 2 views cho Co-Training")

print(f"\nğŸ“Š HOÃ€N THÃ€NH ({len(completed)} items):")
for item in completed:
    print(f"   {item}")

print(f"\nâš ï¸  PARTIAL ({len(partial)} items):")
for item in partial:
    print(f"   {item}")

print(f"\nâŒ Cáº¦N Bá»” SUNG ({len(missing)} items):")
for item in missing:
    print(f"   {item}")

progress = len(completed) / (len(completed) + len(partial) + len(missing)) * 100
print(f"\n{'='*80}")
print(f"TIáº¾N Äá»˜: {progress:.0f}% HOÃ€N THÃ€NH")
print(f"{'='*80}")
